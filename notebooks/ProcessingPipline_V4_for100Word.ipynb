{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83a0B85frbmm",
        "outputId": "d00c22ce-0db6-4cd2-baa4-ab6d35203dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOib17sAn-h7",
        "outputId": "3b0cd25b-eeac-4807-a031-7b58718413a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.7.2 is installed, but it is not compatible with the installed jaxlib version 0.7.1, so it will not be used.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mediapipe as mp\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "PART_NUMBER = 1\n",
        "CSV_FILE = f\"/content/drive/MyDrive/ASL-Project/Data/metadata/1st_Prototype(100_word)/part_4.csv\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/ASL-Project/Data/processed_prototype/1st_prototype_processed_2\"\n",
        "SEQUENCE_LENGTH = 50\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEpJqMiDtCtN"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(CSV_FILE)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH6CCCBxoIQG"
      },
      "source": [
        "# 2. Advanced Preprocessing Logic (V3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCslB4GYn5nV"
      },
      "outputs": [],
      "source": [
        "mp_holistic = mp.solutions.holistic\n",
        "\n",
        "def normalize_hand(pts):\n",
        "    \"\"\"\n",
        "    Normalizes hand landmarks relative to the wrist (point 0).\n",
        "    Scale is determined by the distance between wrist and middle finger MCP (point 9).\n",
        "    Ensures hand shape invariance across users and distances.\n",
        "    \"\"\"\n",
        "    ref = pts[0].copy()  # Wrist\n",
        "    scale = np.linalg.norm(pts[9] - ref)\n",
        "    if scale < 1e-6:\n",
        "        scale = 1.0\n",
        "    return (pts - ref) / scale\n",
        "\n",
        "\n",
        "def compute_torso_stats(pose_landmarks):\n",
        "    \"\"\"\n",
        "    Computes torso center and scale based on shoulders and hips.\n",
        "    Used to normalize pose landmarks to remove impact of camera distance\n",
        "    and body size variations across different subjects.\n",
        "    \"\"\"\n",
        "    torso_center = np.array([0.5, 0.5], dtype=np.float32)\n",
        "    torso_scale = 1.0\n",
        "\n",
        "    try:\n",
        "        ps = pose_landmarks\n",
        "\n",
        "        def get_xy(idx):\n",
        "            lm = ps.landmark[idx]\n",
        "            return np.array([lm.x, lm.y], dtype=np.float32)\n",
        "\n",
        "        left_sh, right_sh = get_xy(11), get_xy(12)\n",
        "        left_hip, right_hip = get_xy(23), get_xy(24)\n",
        "\n",
        "        shoulder_center = (left_sh + right_sh) / 2.0\n",
        "        hip_center = (left_hip + right_hip) / 2.0\n",
        "\n",
        "        torso_center = (shoulder_center + hip_center) / 2.0\n",
        "\n",
        "        shoulder_dist = np.linalg.norm(left_sh - right_sh)\n",
        "        hip_dist = np.linalg.norm(left_hip - right_hip)\n",
        "\n",
        "        torso_scale = max(shoulder_dist, hip_dist, 1e-6)\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return torso_center, float(torso_scale)\n",
        "\n",
        "\n",
        "def extract_features_from_frame(results):\n",
        "    \"\"\"\n",
        "    Extracts a 198-dimension feature vector:\n",
        "    - Pose: 33 points × 2 = 66 values\n",
        "    - Left Hand: 21 points × 3 + wrist_rel = 66 values\n",
        "    - Right Hand: 21 points × 3 + wrist_rel = 66 values\n",
        "    \"\"\"\n",
        "    feat = np.zeros(198, dtype=np.float32)\n",
        "\n",
        "    torso_center = np.array([0.5, 0.5], dtype=np.float32)\n",
        "    torso_scale = 1.0\n",
        "\n",
        "    # 1. Pose (0–65)\n",
        "    if results.pose_landmarks:\n",
        "        torso_center, torso_scale = compute_torso_stats(results.pose_landmarks)\n",
        "        pose_xy = np.array([[lm.x, lm.y] for lm in results.pose_landmarks.landmark], dtype=np.float32)\n",
        "        pose_norm = (pose_xy - torso_center[None, :]) / torso_scale\n",
        "        feat[0:66] = pose_norm.flatten()\n",
        "\n",
        "    # 2. Left Hand (66–131)\n",
        "    if results.left_hand_landmarks:\n",
        "        l_pts = np.array([[lm.x, lm.y, lm.z] for lm in results.left_hand_landmarks.landmark], dtype=np.float32)\n",
        "        feat[66:129] = normalize_hand(l_pts)[:, :3].flatten()\n",
        "\n",
        "        wrist_rel = l_pts[0].copy()\n",
        "        wrist_rel[:2] = (wrist_rel[:2] - torso_center) / torso_scale\n",
        "        wrist_rel[2] /= torso_scale\n",
        "        feat[129:132] = wrist_rel\n",
        "\n",
        "    # 3. Right Hand (132–197)\n",
        "    if results.right_hand_landmarks:\n",
        "        r_pts = np.array([[lm.x, lm.y, lm.z] for lm in results.right_hand_landmarks.landmark], dtype=np.float32)\n",
        "        feat[132:195] = normalize_hand(r_pts)[:, :3].flatten()\n",
        "\n",
        "        wrist_rel = r_pts[0].copy()\n",
        "        wrist_rel[:2] = (wrist_rel[:2] - torso_center) / torso_scale\n",
        "        wrist_rel[2] /= torso_scale\n",
        "        feat[195:198] = wrist_rel\n",
        "\n",
        "    return feat\n",
        "\n",
        "\n",
        "def process_video_pipeline(video_path):\n",
        "    \"\"\"\n",
        "    Reads video and extracts a fixed-length temporal feature sequence.\n",
        "    Steps:\n",
        "    1. Extract features per frame\n",
        "    2. Interpolate missing frames\n",
        "    3. Uniform resampling or padding to SEQUENCE_LENGTH\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        return None\n",
        "\n",
        "    frames_buffer = []\n",
        "\n",
        "    with mp_holistic.Holistic(static_image_mode=False,\n",
        "                              min_detection_confidence=0.5,\n",
        "                              model_complexity=1) as holistic:\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = holistic.process(img_rgb)\n",
        "            feat = extract_features_from_frame(results)\n",
        "\n",
        "            if np.sum(np.abs(feat)) < 1e-6:\n",
        "                frames_buffer.append(None)\n",
        "            else:\n",
        "                frames_buffer.append(feat)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if not frames_buffer:\n",
        "        return None\n",
        "\n",
        "    # Fill missing frames by interpolation\n",
        "    for i in range(len(frames_buffer)):\n",
        "        if frames_buffer[i] is None:\n",
        "            prev_valid = next((frames_buffer[j] for j in range(i - 1, -1, -1)\n",
        "                               if frames_buffer[j] is not None), None)\n",
        "            next_valid = next((frames_buffer[j] for j in range(i + 1, len(frames_buffer))\n",
        "                               if frames_buffer[j] is not None), None)\n",
        "\n",
        "            if prev_valid is not None and next_valid is not None:\n",
        "                frames_buffer[i] = (prev_valid + next_valid) / 2.0\n",
        "            elif prev_valid is not None:\n",
        "                frames_buffer[i] = prev_valid\n",
        "            elif next_valid is not None:\n",
        "                frames_buffer[i] = next_valid\n",
        "            else:\n",
        "                frames_buffer[i] = np.zeros(198, dtype=np.float32)\n",
        "\n",
        "    data_array = np.array(frames_buffer, dtype=np.float32)\n",
        "    length = len(data_array)\n",
        "\n",
        "    # Resample or pad to SEQUENCE_LENGTH\n",
        "    if length == SEQUENCE_LENGTH:\n",
        "        final_data = data_array\n",
        "    elif length < SEQUENCE_LENGTH:\n",
        "        padding = np.zeros((SEQUENCE_LENGTH - length, 198), dtype=np.float32)\n",
        "        final_data = np.vstack([data_array, padding])\n",
        "    else:\n",
        "        indices = np.linspace(0, length - 1, SEQUENCE_LENGTH, dtype=int)\n",
        "        final_data = data_array[indices]\n",
        "\n",
        "    return final_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIUWpfvgp1OI"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(CSV_FILE)\n",
        "\n",
        "print(f\"Total videos: {len(df)}\")\n",
        "print(f\"Words: {df['word'].unique()}\")\n",
        "\n",
        "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "\n",
        "    word = row[\"word\"]\n",
        "    video_path = str(row[\"full_path\"]).strip()\n",
        "\n",
        "    class_dir = os.path.join(OUTPUT_DIR, word)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    vid_name = os.path.basename(video_path).rsplit(\".\", 1)[0]\n",
        "    save_path = os.path.join(class_dir, f\"{vid_name}.npy\")\n",
        "\n",
        "    if os.path.exists(save_path):\n",
        "        continue\n",
        "\n",
        "    if not os.path.exists(video_path):\n",
        "        print(\"Missing:\", video_path)\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        processed_data = process_video_pipeline(video_path)\n",
        "\n",
        "        if processed_data is not None:\n",
        "            np.save(save_path, processed_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {video_path} -> {e}\")\n",
        "\n",
        "print(\"Finished\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4PfyI2Bg2NC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}